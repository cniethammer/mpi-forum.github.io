<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-datatypes/datatypes-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>Examples</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node112">6.1.14. Examples</span></h2>
<a href="node111.htm#Node111"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node98.htm#Node98"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node113.htm#Node113"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node98.htm#Node98"> Derived Datatypes</a>
<b>Next: </b><a href="node113.htm#Node113"> Pack and Unpack</a>
<b>Previous: </b><a href="node111.htm#Node111"> Decoding a Datatype</a>
<p>
  
<P> 
The following examples illustrate the use of derived datatypes.  
<P> 
<br><b> Example</b>  
  
Send and receive a section of a 3D array.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>REAL</b> a(100,100,100), e(9,9,9) 
<b>INTEGER</b> oneslice, twoslice, threeslice, myrank, ierr 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lb, sizeofreal 
<b>INTEGER</b> status(<b>MPI_STATUS_SIZE</b>) 
 
! extract the section a(1:17:2, 3:11, 2:10) 
! and store it <b>in</b> e(:,:,:). 
 
<b>CALL</b> <b>MPI_COMM_RANK</b>(<b>MPI_COMM_WORLD</b>, myrank, ierr) 
 
<b>CALL</b> <b>MPI_TYPE_GET_EXTENT</b>(<b>MPI_REAL</b>, lb, sizeofreal, ierr) 
 
! create datatype for a 1D section 
<b>CALL</b> <b>MPI_TYPE_VECTOR</b>(9, 1, 2, <b>MPI_REAL</b>, oneslice, ierr) 
 
! create datatype for a 2D section 
<b>CALL</b> <b>MPI_TYPE_CREATE_HVECTOR</b>(9, 1, 100*sizeofreal, oneslice, &amp; 
                             twoslice, ierr) 
 
! create datatype for the entire section 
<b>CALL</b> <b>MPI_TYPE_CREATE_HVECTOR</b>(9, 1, 100*100*sizeofreal, twoslice, &amp; 
                             threeslice, ierr) 
 
<b>CALL</b> <b>MPI_TYPE_COMMIT</b>(threeslice, ierr) 
<b>CALL</b> <b>MPI_SENDRECV</b>(a(1,3,2), 1, threeslice, myrank, 0, e, 9*9*9, &amp; 
                  <b>MPI_REAL</b>, myrank, 0, <b>MPI_COMM_WORLD</b>, status, ierr) 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
Copy the (strictly) lower triangular part of a matrix.  
<br> 
<pre style="background-color:#EFEFEF"><tt><b>REAL</b> a(100,100), b(100,100) 
<b>INTEGER</b>  disp(100), blocklen(100), ltype, myrank, ierr 
<b>INTEGER</b> status(<b>MPI_STATUS_SIZE</b>) 
 
! copy lower triangular part of array a 
! onto lower triangular part of array b 
 
<b>CALL</b> <b>MPI_COMM_RANK</b>(<b>MPI_COMM_WORLD</b>, myrank, ierr) 
 
! compute start and size of each column 
<b>DO</b> i=1,100 
   disp(i) = 100*(i-1) + i 
   blocklen(i) = 100-i 
<b>END</b> <b>DO</b> 
 
! create datatype for lower triangular part 
<b>CALL</b> <b>MPI_TYPE_INDEXED</b>(100, blocklen, disp, <b>MPI_REAL</b>, ltype, ierr) 
 
<b>CALL</b> <b>MPI_TYPE_COMMIT</b>(ltype, ierr) 
<b>CALL</b> <b>MPI_SENDRECV</b>(a, 1, ltype, myrank, 0, b, 1, &amp; 
                  ltype, myrank, 0, <b>MPI_COMM_WORLD</b>, status, ierr) 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
Transpose a matrix.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>REAL</b> a(100,100), b(100,100) 
<b>INTEGER</b> row, xpose, myrank, ierr 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lb, sizeofreal 
<b>INTEGER</b> status(<b>MPI_STATUS_SIZE</b>) 
 
! transpose matrix a onto b 
 
<b>CALL</b> <b>MPI_COMM_RANK</b>(<b>MPI_COMM_WORLD</b>, myrank, ierr) 
 
<b>CALL</b> <b>MPI_TYPE_GET_EXTENT</b>(<b>MPI_REAL</b>, lb, sizeofreal, ierr) 
 
! create datatype for one row 
<b>CALL</b> <b>MPI_TYPE_VECTOR</b>(100, 1, 100, <b>MPI_REAL</b>, row, ierr) 
 
! create datatype for matrix <b>in</b> row-major order 
<b>CALL</b> <b>MPI_TYPE_CREATE_HVECTOR</b>(100, 1, sizeofreal, row, xpose, ierr) 
 
<b>CALL</b> <b>MPI_TYPE_COMMIT</b>(xpose, ierr) 
 
! send matrix <b>in</b> row-major order and receive <b>in</b> column major order 
<b>CALL</b> <b>MPI_SENDRECV</b>(a, 1, xpose, myrank, 0, b, 100*100, &amp; 
                  <b>MPI_REAL</b>, myrank, 0, <b>MPI_COMM_WORLD</b>, status, ierr) 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
Another approach to the transpose problem:  
<br> 
<pre style="background-color:#EFEFEF"><tt><b>REAL</b> a(100,100), b(100,100) 
<b>INTEGER</b> row, row1 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lb, sizeofreal 
<b>INTEGER</b> myrank, ierr 
<b>INTEGER</b> status(<b>MPI_STATUS_SIZE</b>) 
 
<b>CALL</b> <b>MPI_COMM_RANK</b>(<b>MPI_COMM_WORLD</b>, myrank, ierr) 
 
! transpose matrix a onto b 
 
<b>CALL</b> <b>MPI_TYPE_GET_EXTENT</b>(<b>MPI_REAL</b>, lb, sizeofreal, ierr) 
 
! create datatype for one row 
<b>CALL</b> <b>MPI_TYPE_VECTOR</b>(100, 1, 100, <b>MPI_REAL</b>, row, ierr) 
 
! create datatype for one row, with the extent of one <b>real</b> number 
lb = 0 
<b>CALL</b> <b>MPI_TYPE_CREATE_RESIZED</b>(row, lb, sizeofreal, row1, ierr) 
 
<b>CALL</b> <b>MPI_TYPE_COMMIT</b>(row1, ierr) 
 
! send 100 rows and receive <b>in</b> column major order 
<b>CALL</b> <b>MPI_SENDRECV</b>(a, 100, row1, myrank, 0, b, 100*100, &amp; 
                  <b>MPI_REAL</b>, myrank, 0, <b>MPI_COMM_WORLD</b>, status, ierr) 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
Use of <font face="sans-serif"> MPI</font> datatypes to manipulate an array of structures.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>struct</b> Partstruct 
{ 
   <b>int</b>    type;   /* particle type */ 
   <b>double</b> d[6];   /* particle coordinates */ 
   <b>char</b>   b[7];   /* some additional information */ 
}; 
 
<b>struct</b> Partstruct    particle[1000]; 
 
<b>int</b>          i, dest, tag; 
<b>MPI_Comm</b>     comm; 
 
 
/* build datatype describing structure */ 
 
<b>MPI_Datatype</b> Particlestruct, Particletype; 
<b>MPI_Datatype</b> type[3] = {<b>MPI_INT</b>, <b>MPI_DOUBLE</b>, <b>MPI_CHAR</b>}; 
<b>int</b>          blocklen[3] = {1, 6, 7}; 
<b>MPI_Aint</b>     disp[3]; 
<b>MPI_Aint</b>     base, lb, sizeofentry; 
 
 
/* compute displacements of structure components */ 
 
<b>MPI_Get_address</b>(particle, disp); 
<b>MPI_Get_address</b>(particle[0].d, disp+1); 
<b>MPI_Get_address</b>(particle[0].b, disp+2); 
base = disp[0]; 
<b>for</b> (i=0; i &lt; 3; i++) disp[i] = <b>MPI_Aint_diff</b>(disp[i], base); 
 
<b>MPI_Type_create_struct</b>(3, blocklen, disp, type, &amp;Particlestruct); 
 
/* Since the compiler may pad the structure, it is best to explicitly 
   set the extent of the MPI datatype <b>for</b> a structure element using 
   <b>MPI_Type_create_resized</b> */ 
 
/* compute extent of the structure */ 
<b>MPI_Get_address</b>(particle+1, &amp;sizeofentry); 
sizeofentry = <b>MPI_Aint_diff</b>(sizeofentry, base); 
 
/* build datatype describing structure */ 
<b>MPI_Type_create_resized</b>(Particlestruct, 0, sizeofentry, &amp;Particletype); 
 
 
/* 4.1: send the entire array */ 
 
<b>MPI_Type_commit</b>(&amp;Particletype); 
<b>MPI_Send</b>(particle, 1000, Particletype, dest, tag, comm); 
 
 
/* 4.2: send only the entries of type zero particles, 
        preceded by the number of such entries */ 
 
<b>MPI_Datatype</b> Zparticles;   /* datatype describing all particles 
                              with type zero (needs to be recomputed 
                              <b>if</b> types change) */ 
<b>MPI_Datatype</b> Ztype; 
 
<b>int</b>          zdisp[1000]; 
<b>int</b>          zblock[1000], j, k; 
<b>int</b>          zzblock[2] = {1,1}; 
<b>MPI_Aint</b>     zzdisp[2]; 
<b>MPI_Datatype</b> zztype[2]; 
 
/* compute displacements of type zero particles */ 
j = 0; 
<b>for</b> (i=0; i &lt; 1000; i++) 
   <b>if</b> (particle[i].type == 0) 
      { 
        zdisp[j] = i; 
        zblock[j] = 1; 
        j++; 
      } 
 
/* create datatype <b>for</b> type zero particles  */ 
<b>MPI_Type_indexed</b>(j, zblock, zdisp, Particletype, &amp;Zparticles); 
 
/* prepend particle count */ 
<b>MPI_Get_address</b>(&amp;j, zzdisp); 
<b>MPI_Get_address</b>(particle, zzdisp+1); 
zztype[0] = <b>MPI_INT</b>; 
zztype[1] = Zparticles; 
<b>MPI_Type_create_struct</b>(2, zzblock, zzdisp, zztype, &amp;Ztype); 
 
<b>MPI_Type_commit</b>(&amp;Ztype); 
<b>MPI_Send</b>(<b>MPI_BOTTOM</b>, 1, Ztype, dest, tag, comm); 
 
 
/* A probably more efficient way of defining Zparticles */ 
 
/* consecutive particles with index zero are handled as one block */ 
j=0; 
<b>for</b> (i=0; i &lt; 1000; i++) 
   <b>if</b> (particle[i].type == 0) 
      { 
         <b>for</b> (k=i+1; (k &lt; 1000)&amp;&amp;(particle[k].type == 0); k++); 
         zdisp[j] = i; 
         zblock[j] = k-i; 
         j++; 
         i = k; 
      } 
<b>MPI_Type_indexed</b>(j, zblock, zdisp, Particletype, &amp;Zparticles); 
 
 
/* 4.3: send the first two coordinates of all entries */ 
 
<b>MPI_Datatype</b> Allpairs;      /* datatype <b>for</b> all pairs of coordinates */ 
 
<b>MPI_Type_get_extent</b>(Particletype, &amp;lb, &amp;sizeofentry); 
 
/* sizeofentry can also be computed by subtracting the address 
   of particle[0] from the address of particle[1] */ 
 
<b>MPI_Type_create_hvector</b>(1000, 2, sizeofentry, <b>MPI_DOUBLE</b>, &amp;Allpairs); 
<b>MPI_Type_commit</b>(&amp;Allpairs); 
<b>MPI_Send</b>(particle[0].d, 1, Allpairs, dest, tag, comm); 
 
/* an alternative solution to 4.3 */ 
 
<b>MPI_Datatype</b> Twodouble; 
 
<b>MPI_Type_contiguous</b>(2, <b>MPI_DOUBLE</b>, &amp;Twodouble); 
 
<b>MPI_Datatype</b> Onepair;   /* datatype <b>for</b> one pair of coordinates, with 
                          the extent of one particle entry */ 
 
<b>MPI_Type_create_resized</b>(Twodouble, 0, sizeofentry, &amp;Onepair ); 
<b>MPI_Type_commit</b>(&amp;Onepair); 
<b>MPI_Send</b>(particle[0].d, 1000, Onepair, dest, tag, comm); 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
The same manipulations as in the previous example, but use absolute  
addresses in datatypes.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>struct</b> Partstruct 
{ 
    <b>int</b>    type; 
    <b>double</b> d[6]; 
    <b>char</b>   b[7]; 
}; 
 
<b>struct</b> Partstruct particle[1000]; 
 
/* build datatype describing first array entry */ 
 
<b>MPI_Datatype</b> Particletype; 
<b>MPI_Datatype</b> type[3] = {<b>MPI_INT</b>, <b>MPI_DOUBLE</b>, <b>MPI_CHAR</b>}; 
<b>int</b>          block[3] = {1, 6, 7}; 
<b>MPI_Aint</b>     disp[3]; 
 
<b>MPI_Get_address</b>(particle, disp); 
<b>MPI_Get_address</b>(particle[0].d, disp+1); 
<b>MPI_Get_address</b>(particle[0].b, disp+2); 
<b>MPI_Type_create_struct</b>(3, block, disp, type, &amp;Particletype); 
 
/* Particletype describes first array entry -- using absolute 
   addresses */ 
 
/* 5.1: send the entire array */ 
 
<b>MPI_Type_commit</b>(&amp;Particletype); 
<b>MPI_Send</b>(<b>MPI_BOTTOM</b>, 1000, Particletype, dest, tag, comm); 
 
 
/* 5.2: send the entries of type zero, 
        preceded by the number of such entries */ 
 
<b>MPI_Datatype</b> Zparticles, Ztype; 
 
<b>int</b>          zdisp[1000]; 
<b>int</b>          zblock[1000], i, j, k; 
<b>int</b>          zzblock[2] = {1,1}; 
<b>MPI_Datatype</b> zztype[2]; 
<b>MPI_Aint</b>     zzdisp[2]; 
 
j=0; 
<b>for</b> (i=0; i &lt; 1000; i++) 
    <b>if</b> (particle[i].type == 0) 
        { 
            <b>for</b> (k=i+1; (k &lt; 1000)&amp;&amp;(particle[k].type == 0); k++); 
            zdisp[j] = i; 
            zblock[j] = k-i; 
            j++; 
            i = k; 
        } 
<b>MPI_Type_indexed</b>(j, zblock, zdisp, Particletype, &amp;Zparticles); 
/* Zparticles describe particles with type zero, using 
   their absolute addresses*/ 
 
/* prepend particle count */ 
<b>MPI_Get_address</b>(&amp;j, zzdisp); 
zzdisp[1] = (<b>MPI_Aint</b>)0; 
zztype[0] = <b>MPI_INT</b>; 
zztype[1] = Zparticles; 
<b>MPI_Type_create_struct</b>(2, zzblock, zzdisp, zztype, &amp;Ztype); 
 
<b>MPI_Type_commit</b>(&amp;Ztype); 
<b>MPI_Send</b>(<b>MPI_BOTTOM</b>, 1, Ztype, dest, tag, comm); 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
This example shows how datatypes can be used to handle unions.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>union</b> { 
   <b>int</b>     ival; 
   <b>float</b>   fval; 
      } u[1000]; 
 
<b>int</b>     i, utype; 
 
/* All entries of u have identical type; variable 
   utype keeps track of their current type */ 
 
<b>MPI_Datatype</b>   mpi_utype[2]; 
<b>MPI_Aint</b>       ubase, extent; 
 
/* compute an MPI datatype <b>for</b> each possible <b>union</b> type; 
   assume values are left-aligned in <b>union</b> storage. */ 
 
<b>MPI_Get_address</b>(u, &amp;ubase); 
<b>MPI_Get_address</b>(u+1, &amp;extent); 
extent = <b>MPI_Aint_diff</b>(extent, ubase); 
 
<b>MPI_Type_create_resized</b>(<b>MPI_INT</b>, 0, extent, &amp;mpi_utype[0]); 
 
<b>MPI_Type_create_resized</b>(<b>MPI_FLOAT</b>, 0, extent, &amp;mpi_utype[1]); 
 
<b>for</b>(i=0; i&lt;2; i++) <b>MPI_Type_commit</b>(&amp;mpi_utype[i]); 
 
/* actual communication */ 
<b>MPI_Send</b>(u, 1000, mpi_utype[utype], dest, tag, comm); 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
This  
example shows how a datatype can be decoded.  The routine  
<tt>printdatatype</tt> prints out the elements of the datatype.  Note the use  
of <font face="sans-serif"> MPI_Type_free</font> for datatypes that are not predefined.  
<br> 
<pre style="background-color:#EFEFEF"><tt>/* 
  Example of decoding a datatype. 
 
  Returns 0 <b>if</b> the datatype is predefined, 1 otherwise 
 */ 
<b>#include</b> &lt;stdio.h&gt; 
<b>#include</b> &lt;stdlib.h&gt; 
<b>#include</b> "mpi.h" 
<b>int</b> printdatatype(<b>MPI_Datatype</b> datatype) 
{ 
    <b>int</b> *array_of_ints; 
    <b>MPI_Aint</b> *array_of_adds; 
    <b>MPI_Datatype</b> *array_of_dtypes; 
    <b>int</b> num_ints, num_adds, num_dtypes, combiner; 
    <b>int</b> i; 
 
    <b>MPI_Type_get_envelope</b>(datatype, 
                          &amp;num_ints, &amp;num_adds, &amp;num_dtypes, &amp;combiner); 
    <b>switch</b> (combiner) { 
    <b>case</b> <b>MPI_COMBINER_NAMED</b>: 
        printf("Datatype is named:"); 
        /* To print the specific type, we can match against the 
           predefined forms. We can NOT use a <b>switch</b> statement here 
           We could also use <b>MPI_TYPE_GET_NAME</b> <b>if</b> we prefered to use 
           names that the user may have changed. 
         */ 
        <b>if</b>      (datatype == <b>MPI_INT</b>)    printf("MPI_INT\n"); 
        <b>else</b> <b>if</b> (datatype == <b>MPI_DOUBLE</b>) printf("MPI_DOUBLE\n"); 
        ... <b>else</b> test <b>for</b> other types ... 
        <b>return</b> 0; 
        <b>break</b>; 
    <b>case</b> <b>MPI_COMBINER_STRUCT</b>: 
        printf("Datatype is struct containing"); 
        array_of_ints   = (<b>int</b> *)malloc(num_ints * <b>sizeof</b>(<b>int</b>)); 
        array_of_adds   = 
                   (<b>MPI_Aint</b> *) malloc(num_adds * <b>sizeof</b>(<b>MPI_Aint</b>)); 
        array_of_dtypes = (<b>MPI_Datatype</b> *) 
            malloc(num_dtypes * <b>sizeof</b>(<b>MPI_Datatype</b>)); 
        <b>MPI_Type_get_contents</b>(datatype, num_ints, num_adds, num_dtypes, 
                         array_of_ints, array_of_adds, array_of_dtypes); 
        printf(" %d datatypes:\n", array_of_ints[0]); 
        <b>for</b> (i=0; i&lt;array_of_ints[0]; i++) { 
            printf("blocklength %d, displacement %ld, type:\n", 
                   array_of_ints[i+1], (<b>long</b>)array_of_adds[i]); 
            <b>if</b> (printdatatype(array_of_dtypes[i])) { 
                /* Note that we free the type ONLY <b>if</b> it 
                   is not predefined */ 
                <b>MPI_Type_free</b>(&amp;array_of_dtypes[i]); 
            } 
        } 
        free(array_of_ints); 
        free(array_of_adds); 
        free(array_of_dtypes); 
        <b>break</b>; 
        ... other combiner values ... 
    <b>default</b>: 
        printf("Unrecognized combiner type\n"); 
    } 
    <b>return</b> 1; 
} 
</tt></pre> 
  
  
<P> 

<P>
<hr>
<a href="node111.htm#Node111"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node98.htm#Node98"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node113.htm#Node113"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node98.htm#Node98"> Derived Datatypes</a>
<b>Next: </b><a href="node113.htm#Node113"> Pack and Unpack</a>
<b>Previous: </b><a href="node111.htm#Node111"> Decoding a Datatype</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
