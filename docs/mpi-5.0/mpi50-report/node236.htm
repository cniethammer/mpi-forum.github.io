<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-topol/topol-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>Neighborhood Alltoall</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node236">9.6.2. Neighborhood Alltoall</span></h2>
<a href="node235.htm#Node235"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node234.htm#Node234"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node237.htm#Node237"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node234.htm#Node234"> Neighborhood Collective Communication on Virtual Topologies</a>
<b>Next: </b><a href="node237.htm#Node237"> Nonblocking Neighborhood Communication on Process Topologies</a>
<b>Previous: </b><a href="node235.htm#Node235"> Neighborhood Gather</a>
<p>
  
<P> 
In the neighborhood alltoall operation, each <font face="sans-serif"> MPI</font> process <i>i</i> receives data items from each <font face="sans-serif"> MPI</font> process  
<i>j</i> if an edge <i>(j,i)</i> exists in the topology graph or Cartesian  
topology. Similarly, each <font face="sans-serif"> MPI</font> process <i>i</i> sends data items to all <font face="sans-serif"> MPI</font> processes  
<i>j</i> where an edge <i>(i,j)</i> exists. This call is more general than  
<font face="sans-serif"> MPI_NEIGHBOR_ALLGATHER</font> in that different data items can be  
sent to each neighbor. The <i>k</i>-th block in send buffer is sent to the  
<i>k</i>-th neighboring <font face="sans-serif"> MPI</font> process and the <i>l</i>-th block in the receive buffer is  
received from the <i>l</i>-th neighbor.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_NEIGHBOR_ALLTOALL(<span style="white-space:nowrap">sendbuf</span>, <span style="white-space:nowrap">sendcount</span>, <span style="white-space:nowrap">sendtype</span>, <span style="white-space:nowrap">recvbuf</span>, <span style="white-space:nowrap">recvcount</span>, <span style="white-space:nowrap">recvtype</span>, <span style="white-space:nowrap">comm</span>)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendbuf</TD><TD>starting address of send buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendcount</TD><TD>number of elements sent to each neighbor (nonnegative integer)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendtype</TD><TD>datatype of send buffer elements (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> OUT</span> recvbuf</TD><TD>starting address of receive buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> recvcount</TD><TD>number of elements received from each neighbor (nonnegative integer)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> recvtype</TD><TD>datatype of receive buffer elements (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> comm</TD><TD>communicator with associated virtual topology (handle)</TD></TR>  
</TABLE>  
  <b> C binding</b><br>  <tt> int MPI_Neighbor_alltoall(const void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm) <br></tt>  
  
  <tt> int MPI_Neighbor_alltoall_c(const void *sendbuf, MPI_Count sendcount, MPI_Datatype sendtype, void *recvbuf, MPI_Count recvcount, MPI_Datatype recvtype, MPI_Comm comm) <br></tt>  
  <b> Fortran 2008 binding</b><br>  <tt> MPI_Neighbor_alltoall(sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, comm, ierror) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: <span style="white-space:nowrap">sendbuf</span><br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">sendcount</span>, <span style="white-space:nowrap">recvcount</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">sendtype</span>, <span style="white-space:nowrap">recvtype</span><br>TYPE(*), DIMENSION(..) :: <span style="white-space:nowrap">recvbuf</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <tt> MPI_Neighbor_alltoall(sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, comm, ierror) !(_c) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: <span style="white-space:nowrap">sendbuf</span><br>INTEGER(KIND=MPI_COUNT_KIND), INTENT(IN) :: <span style="white-space:nowrap">sendcount</span>, <span style="white-space:nowrap">recvcount</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">sendtype</span>, <span style="white-space:nowrap">recvtype</span><br>TYPE(*), DIMENSION(..) :: <span style="white-space:nowrap">recvbuf</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <b> Fortran binding</b><br>  <tt> MPI_NEIGHBOR_ALLTOALL(SENDBUF, SENDCOUNT, SENDTYPE, RECVBUF, RECVCOUNT, RECVTYPE, COMM, IERROR) <br> &lt;type&gt; <span style="white-space:nowrap">SENDBUF(*)</span>, <span style="white-space:nowrap">RECVBUF(*)</span><br>INTEGER <span style="white-space:nowrap">SENDCOUNT</span>, <span style="white-space:nowrap">SENDTYPE</span>, <span style="white-space:nowrap">RECVCOUNT</span>, <span style="white-space:nowrap">RECVTYPE</span>, <span style="white-space:nowrap">COMM</span>, <span style="white-space:nowrap">IERROR</span> <br></tt>  
<P> 
The <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALL</font> procedure supports Cartesian communicators, graph communicators, and  
distributed graph communicators as described  
in Section <a href="node234.htm#Node234">Neighborhood Collective Communication on Virtual Topologies</a>.  
If <font face="sans-serif"> comm</font> is a distributed graph communicator, the outcome is as if each  
<font face="sans-serif"> MPI</font> process executed sends to each of its outgoing neighbors and receives from  
each of its incoming neighbors:  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>MPI_Dist_graph_neighbors_count</b>(comm, &amp;indegree, &amp;outdegree, &amp;weighted); 
<b>int</b> *srcs=(<b>int</b>*)malloc(indegree*<b>sizeof</b>(<b>int</b>)); 
<b>int</b> *dsts=(<b>int</b>*)malloc(outdegree*<b>sizeof</b>(<b>int</b>)); 
<b>MPI_Dist_graph_neighbors</b>(comm, indegree, srcs, <b>MPI_UNWEIGHTED</b>, 
                         outdegree, dsts, <b>MPI_UNWEIGHTED</b>); 
<b>int</b> k; 
 
/* assume sendbuf and recvbuf are of type (<b>char</b>*) */ 
<b>for</b>(k=0; k&lt;outdegree; ++k) 
  <b>MPI_Isend</b>(sendbuf+k*sendcount*extent(sendtype), sendcount, sendtype, 
            dsts[k],...);  
 
<b>for</b>(k=0; k&lt;indegree; ++k) 
  <b>MPI_Irecv</b>(recvbuf+k*recvcount*extent(recvtype), recvcount, recvtype, 
            srcs[k],...); 
 
<b>MPI_Waitall</b>(...); 
</tt></pre> 
  
<P> 
The type signature associated with <font face="sans-serif"> sendcount</font>, <font face="sans-serif"> sendtype</font>  
at an <font face="sans-serif"> MPI</font> process must be equal to the type signature associated with  
<font face="sans-serif"> recvcount</font>, <font face="sans-serif"> recvtype</font> at any other <font face="sans-serif"> MPI</font> process.  
This implies that the amount of data sent must be equal to the  
amount of data received, pairwise between every pair of  
communicating <font face="sans-serif"> MPI</font> processes.  
Distinct type maps between sender and receiver are still allowed.  
 <P> 
The ``in place'' option is not meaningful for this operation.  
<P> 
All arguments are significant on all <font face="sans-serif"> MPI</font> processes and the argument  
<font face="sans-serif"> comm</font> must have identical values on all <font face="sans-serif"> MPI</font> processes.  
<P> 
<br><b> Example</b>  
  
Buffer usage of <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALL</font> in the case of a Cartesian virtual topology.  
<P> 
For a halo communication on a Cartesian grid, the buffer usage  
in a given direction <font face="sans-serif"> d</font> with  <font face="sans-serif"> dims[d]=3</font> and  <font face="sans-serif"> 1</font>,   
respectively during creation of the communicator is described  
in Figure <a href="node236.htm#Figure23">23</a>.  
<P> 
The figure may apply to any (or multiple) directions in  
the Cartesian topology. The grey buffers are required in all  
cases but are only accessed if during creation of the communicator,  
<font face="sans-serif"> periods[d]</font> was defined as nonzero (in C) or <font face="sans-serif"> .TRUE.</font> (in Fortran).  
<P> 
If <font face="sans-serif"> sendbuf</font> and <font face="sans-serif"> recvbuf</font> are declared as <font face="sans-serif"> (</font>char *) and contain a sequence of buffers  
each described by <font face="sans-serif"> sendcount</font>,<font face="sans-serif"> sendtype</font> and  
<font face="sans-serif"> recvbuf</font>,<font face="sans-serif"> recvtype</font>, then after <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALL</font> on a Cartesian communicator returned, the content  
of the <font face="sans-serif"> recvbuf</font> is as if the following code is executed:  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>MPI_Cartdim_get</b>(comm, &amp;ndims); 
<b>MPI_Type_get_extent</b>(sendtype, &amp;send_lb, &amp;send_extent); 
<b>MPI_Type_get_extent</b>(recvtype, &amp;recv_lb, &amp;recv_extent); 
<b>for</b>( /*direction*/ d=0; d &lt; ndims; d++) { 
    <b>MPI_Cart_shift</b>(comm, /*direction*/ d, /*disp*/ 1, &amp;rank_source, &amp;rank_dest); 
    <b>MPI_Sendrecv</b>(sendbuf+(d*2`\underline{+0}')*sendcount*send_extent, 
                                 sendcount,sendtype,`\underline{rank\_source}',/*sendtag*/d*2, 
                 recvbuf+(d*2`\underline{+1}')*recvcount*recv_extent, 
                                 recvcount,recvtype,`\underline{rank\_dest}', /*recvtag*/ d*2, 
                 comm,&amp;status);/*communication in direction of displacment -1*/ 
    <b>MPI_Sendrecv</b>(sendbuf+(d*2`\underline{+1}')*sendcount*send_extent, 
                                 sendcount,sendtype,`\underline{rank\_dest}', /*sendtag*/ d*2+1, 
                 recvbuf+(d*2`\underline{+0}')*recvcount*recv_extent, 
                                 recvcount,recvtype,`\underline{rank\_source}',/*recvtag*/d*2+1, 
                 comm,&amp;status);/*communication in direction of displacment +1*/ 
} 
</tt></pre> 
  
<P> 
The first call to <font face="sans-serif"> MPI_Sendrecv</font> implements the solid arrows' communication pattern  
in each diagram of Figure <a href="node236.htm#Figure23">23</a>, whereas the second call is for  
the dashed arrows' pattern.  
  
<P> 
  <div style="text-align:center"><P><img width=1170 height=525 src="cart_neighbor_alltoall.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 23: </b><span id="Figure23">Cartesian neighborhood alltoall example for 3 and 1 <font face="sans-serif"> MPI</font> processes in a dimension</span><P> 
  
    
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
For a Cartesian topology, if the grid in a  
direction <font face="sans-serif"> d</font> is periodic and <font face="sans-serif"> dims[d]</font> is equal to 1 or 2,  
then <font face="sans-serif"> rank_source</font> and <font face="sans-serif"> rank_dest</font> are identical,   
but still all <font face="sans-serif"> ndims</font> send and <font face="sans-serif"> ndims</font> receive operations  
use different buffers.   
If in this case, the two send and receive operations per direction or  
of all directions are internally parallelized, then the several send and  
receive operations for the same sender-receiver <font face="sans-serif"> MPI</font> process pair shall be  
initiated in the same sequence on sender and receiver side or  
they shall be distinguished by different tags.  
The code above shows a valid sequence of operations and tags.  
 (<em> End of advice to implementors.</em>) <br> 
The vector variant of <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALL</font> allows  
sending/receiving different numbers of elements to and from each neighbor.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_NEIGHBOR_ALLTOALLV(<span style="white-space:nowrap">sendbuf</span>, <span style="white-space:nowrap">sendcounts</span>, <span style="white-space:nowrap">sdispls</span>, <span style="white-space:nowrap">sendtype</span>, <span style="white-space:nowrap">recvbuf</span>, <span style="white-space:nowrap">recvcounts</span>, <span style="white-space:nowrap">rdispls</span>, <span style="white-space:nowrap">recvtype</span>, <span style="white-space:nowrap">comm</span>)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendbuf</TD><TD>starting address of send buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendcounts</TD><TD>nonnegative integer array (of length outdegree) specifying the number of elements to send to each neighbor</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sdispls</TD><TD>integer array (of length outdegree). Entry <font face="sans-serif"> j</font> specifies the displacement (relative to <font face="sans-serif"> sendbuf</font>) from which to send the outgoing data to neighbor <font face="sans-serif"> j</font></TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendtype</TD><TD>datatype of send buffer elements (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> OUT</span> recvbuf</TD><TD>starting address of receive buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> recvcounts</TD><TD>nonnegative integer array (of length indegree) specifying the number of elements that are received from each neighbor</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> rdispls</TD><TD>integer array (of length indegree). Entry <font face="sans-serif"> i</font> specifies the displacement (relative to <font face="sans-serif"> recvbuf</font>) at which to place the incoming data from neighbor <font face="sans-serif"> i</font></TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> recvtype</TD><TD>datatype of receive buffer elements (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> comm</TD><TD>communicator with associated virtual topology (handle)</TD></TR>  
</TABLE>  
  <b> C binding</b><br>  <tt> int MPI_Neighbor_alltoallv(const void *sendbuf, const int sendcounts[], const int sdispls[], MPI_Datatype sendtype, void *recvbuf, const int recvcounts[], const int rdispls[], MPI_Datatype recvtype, MPI_Comm comm) <br></tt>  
  
  <tt> int MPI_Neighbor_alltoallv_c(const void *sendbuf, const MPI_Count sendcounts[], const MPI_Aint sdispls[], MPI_Datatype sendtype, void *recvbuf, const MPI_Count recvcounts[], const MPI_Aint rdispls[], MPI_Datatype recvtype, MPI_Comm comm) <br></tt>  
  <b> Fortran 2008 binding</b><br>  <tt> MPI_Neighbor_alltoallv(sendbuf, sendcounts, sdispls, sendtype, recvbuf, recvcounts, rdispls, recvtype, comm, ierror) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: <span style="white-space:nowrap">sendbuf</span><br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">sendcounts(*)</span>, <span style="white-space:nowrap">sdispls(*)</span>, <span style="white-space:nowrap">recvcounts(*)</span>, <span style="white-space:nowrap">rdispls(*)</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">sendtype</span>, <span style="white-space:nowrap">recvtype</span><br>TYPE(*), DIMENSION(..) :: <span style="white-space:nowrap">recvbuf</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <tt> MPI_Neighbor_alltoallv(sendbuf, sendcounts, sdispls, sendtype, recvbuf, recvcounts, rdispls, recvtype, comm, ierror) !(_c) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: <span style="white-space:nowrap">sendbuf</span><br>INTEGER(KIND=MPI_COUNT_KIND), INTENT(IN) :: <span style="white-space:nowrap">sendcounts(*)</span>, <span style="white-space:nowrap">recvcounts(*)</span><br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: <span style="white-space:nowrap">sdispls(*)</span>, <span style="white-space:nowrap">rdispls(*)</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">sendtype</span>, <span style="white-space:nowrap">recvtype</span><br>TYPE(*), DIMENSION(..) :: <span style="white-space:nowrap">recvbuf</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <b> Fortran binding</b><br>  <tt> MPI_NEIGHBOR_ALLTOALLV(SENDBUF, SENDCOUNTS, SDISPLS, SENDTYPE, RECVBUF, RECVCOUNTS, RDISPLS, RECVTYPE, COMM, IERROR) <br> &lt;type&gt; <span style="white-space:nowrap">SENDBUF(*)</span>, <span style="white-space:nowrap">RECVBUF(*)</span><br>INTEGER <span style="white-space:nowrap">SENDCOUNTS(*)</span>, <span style="white-space:nowrap">SDISPLS(*)</span>, <span style="white-space:nowrap">SENDTYPE</span>, <span style="white-space:nowrap">RECVCOUNTS(*)</span>, <span style="white-space:nowrap">RDISPLS(*)</span>, <span style="white-space:nowrap">RECVTYPE</span>, <span style="white-space:nowrap">COMM</span>, <span style="white-space:nowrap">IERROR</span> <br></tt>  
<P> 
  
The <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALLV</font> procedure supports Cartesian communicators, graph communicators, and  
distributed graph communicators as described  
in Section <a href="node234.htm#Node234">Neighborhood Collective Communication on Virtual Topologies</a>.  
If <font face="sans-serif"> comm</font> is a distributed graph communicator, the outcome is as if each  
<font face="sans-serif"> MPI</font> process executed sends to each of its outgoing neighbors and receives from  
each of its incoming neighbors:  
<P> 
  
<br> 
<pre style="background-color:#EFEFEF"><tt><b>MPI_Dist_graph_neighbors_count</b>(comm, &amp;indegree, &amp;outdegree, &amp;weighted); 
<b>int</b> *srcs=(<b>int</b>*)malloc(indegree*<b>sizeof</b>(<b>int</b>)); 
<b>int</b> *dsts=(<b>int</b>*)malloc(outdegree*<b>sizeof</b>(<b>int</b>)); 
<b>MPI_Dist_graph_neighbors</b>(comm, indegree, srcs, <b>MPI_UNWEIGHTED</b>, 
                         outdegree, dsts, <b>MPI_UNWEIGHTED</b>); 
<b>int</b> k; 
 
/* assume sendbuf and recvbuf are of type (<b>char</b>*) */ 
<b>for</b>(k=0; k&lt;outdegree; ++k) 
  <b>MPI_Isend</b>(sendbuf+sdispls[k]*extent(sendtype), sendcounts[k], 
            sendtype, dsts[k],...); 
 
<b>for</b>(k=0; k&lt;indegree; ++k) 
  <b>MPI_Irecv</b>(recvbuf+rdispls[k]*extent(recvtype), recvcounts[k], 
            recvtype, srcs[k],...); 
 
<b>MPI_Waitall</b>(...); 
</tt></pre> 
  
<P> 
The type signature associated with  
<font face="sans-serif"> sendcounts</font><font face="sans-serif"> [k]</font>, <font face="sans-serif"> sendtype</font>  
with <font face="sans-serif"> dsts[k]=<i>j</i></font> at <font face="sans-serif"> MPI</font> process <i>i</i>  
must be equal to the type signature associated with  
<font face="sans-serif"> recvcounts</font><font face="sans-serif"> [l]</font>, <font face="sans-serif"> recvtype</font>  
with <font face="sans-serif"> srcs[l]=<i>i</i></font> at <font face="sans-serif"> MPI</font> process <i>j</i>.  
This implies that the amount of data sent must be equal to the  
amount of data received, pairwise between every pair of  
communicating <font face="sans-serif"> MPI</font> processes.  
Distinct type maps between sender and receiver are still allowed.  
The data in the <font face="sans-serif"> sendbuf</font> beginning at offset   
<font face="sans-serif"> sdispls</font><font face="sans-serif"> [k]</font> elements (in terms of the <font face="sans-serif"> sendtype</font>)   
is sent to the <font face="sans-serif"> k</font>-th outgoing neighbor.  
The data received from the <font face="sans-serif"> l</font>-th incoming neighbor is placed  
into <font face="sans-serif"> recvbuf</font> beginning at offset <font face="sans-serif"> rdispls</font><font face="sans-serif"> [l]</font>  
elements (in terms of the <font face="sans-serif"> recvtype</font>).   
 <P> 
The ``in place'' option is not meaningful for this operation.  
<P> 
All arguments are significant on all <font face="sans-serif"> MPI</font> processes and the argument  
<font face="sans-serif"> comm</font> must have identical values on all <font face="sans-serif"> MPI</font> processes.  
<P> 
<font face="sans-serif"> MPI_NEIGHBOR_ALLTOALLW</font> allows one to send and receive with  
different datatypes to and from each neighbor.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_NEIGHBOR_ALLTOALLW(<span style="white-space:nowrap">sendbuf</span>, <span style="white-space:nowrap">sendcounts</span>, <span style="white-space:nowrap">sdispls</span>, <span style="white-space:nowrap">sendtypes</span>, <span style="white-space:nowrap">recvbuf</span>, <span style="white-space:nowrap">recvcounts</span>, <span style="white-space:nowrap">rdispls</span>, <span style="white-space:nowrap">recvtypes</span>, <span style="white-space:nowrap">comm</span>)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendbuf</TD><TD>starting address of send buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendcounts</TD><TD>nonnegative integer array (of length outdegree) specifying the number of elements to send to each neighbor</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sdispls</TD><TD>integer array (of length outdegree). Entry <font face="sans-serif"> j</font> specifies the displacement in bytes (relative to <font face="sans-serif"> sendbuf</font>) from which to take the outgoing data destined for neighbor <font face="sans-serif"> j</font> (array of integers)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendtypes</TD><TD>array of datatypes (of length outdegree). Entry <font face="sans-serif"> j</font> specifies the type of data to send to neighbor <font face="sans-serif"> j</font> (array of handles)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> OUT</span> recvbuf</TD><TD>starting address of receive buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> recvcounts</TD><TD>nonnegative integer array (of length indegree) specifying the number of elements that are received from each neighbor</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> rdispls</TD><TD>integer array (of length indegree). Entry <font face="sans-serif"> i</font> specifies the displacement in bytes (relative to <font face="sans-serif"> recvbuf</font>) at which to place the incoming data from neighbor <font face="sans-serif"> i</font> (array of integers)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> recvtypes</TD><TD>array of datatypes (of length indegree). Entry <font face="sans-serif"> i</font> specifies the type of data received from neighbor <font face="sans-serif"> i</font> (array of handles)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> comm</TD><TD>communicator with associated virtual topology (handle)</TD></TR>  
</TABLE>  
  <b> C binding</b><br>  <tt> int MPI_Neighbor_alltoallw(const void *sendbuf, const int sendcounts[], const MPI_Aint sdispls[], const MPI_Datatype sendtypes[], void *recvbuf, const int recvcounts[], const MPI_Aint rdispls[], const MPI_Datatype recvtypes[], MPI_Comm comm) <br></tt>  
  
  <tt> int MPI_Neighbor_alltoallw_c(const void *sendbuf, const MPI_Count sendcounts[], const MPI_Aint sdispls[], const MPI_Datatype sendtypes[], void *recvbuf, const MPI_Count recvcounts[], const MPI_Aint rdispls[], const MPI_Datatype recvtypes[], MPI_Comm comm) <br></tt>  
  <b> Fortran 2008 binding</b><br>  <tt> MPI_Neighbor_alltoallw(sendbuf, sendcounts, sdispls, sendtypes, recvbuf, recvcounts, rdispls, recvtypes, comm, ierror) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: <span style="white-space:nowrap">sendbuf</span><br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">sendcounts(*)</span>, <span style="white-space:nowrap">recvcounts(*)</span><br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: <span style="white-space:nowrap">sdispls(*)</span>, <span style="white-space:nowrap">rdispls(*)</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">sendtypes(*)</span>, <span style="white-space:nowrap">recvtypes(*)</span><br>TYPE(*), DIMENSION(..) :: <span style="white-space:nowrap">recvbuf</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <tt> MPI_Neighbor_alltoallw(sendbuf, sendcounts, sdispls, sendtypes, recvbuf, recvcounts, rdispls, recvtypes, comm, ierror) !(_c) <br> TYPE(*), DIMENSION(..), INTENT(IN) :: <span style="white-space:nowrap">sendbuf</span><br>INTEGER(KIND=MPI_COUNT_KIND), INTENT(IN) :: <span style="white-space:nowrap">sendcounts(*)</span>, <span style="white-space:nowrap">recvcounts(*)</span><br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: <span style="white-space:nowrap">sdispls(*)</span>, <span style="white-space:nowrap">rdispls(*)</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">sendtypes(*)</span>, <span style="white-space:nowrap">recvtypes(*)</span><br>TYPE(*), DIMENSION(..) :: <span style="white-space:nowrap">recvbuf</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <b> Fortran binding</b><br>  <tt> MPI_NEIGHBOR_ALLTOALLW(SENDBUF, SENDCOUNTS, SDISPLS, SENDTYPES, RECVBUF, RECVCOUNTS, RDISPLS, RECVTYPES, COMM, IERROR) <br> &lt;type&gt; <span style="white-space:nowrap">SENDBUF(*)</span>, <span style="white-space:nowrap">RECVBUF(*)</span><br>INTEGER <span style="white-space:nowrap">SENDCOUNTS(*)</span>, <span style="white-space:nowrap">SENDTYPES(*)</span>, <span style="white-space:nowrap">RECVCOUNTS(*)</span>, <span style="white-space:nowrap">RECVTYPES(*)</span>, <span style="white-space:nowrap">COMM</span>, <span style="white-space:nowrap">IERROR</span><br>INTEGER(KIND=MPI_ADDRESS_KIND) <span style="white-space:nowrap">SDISPLS(*)</span>, <span style="white-space:nowrap">RDISPLS(*)</span> <br></tt>  
<P> 
The <font face="sans-serif"> MPI_NEIGHBOR_ALLTOALLW</font> procedure supports Cartesian communicators, graph communicators, and  
distributed graph communicators as described  
in Section <a href="node234.htm#Node234">Neighborhood Collective Communication on Virtual Topologies</a>.  
If <font face="sans-serif"> comm</font> is a distributed graph communicator, the outcome is as if each  
<font face="sans-serif"> MPI</font> process executed sends to each of its outgoing neighbors and receives from  
each of its incoming neighbors:  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>MPI_Dist_graph_neighbors_count</b>(comm, &amp;indegree, &amp;outdegree, &amp;weighted); 
<b>int</b> *srcs=(<b>int</b>*)malloc(indegree*<b>sizeof</b>(<b>int</b>)); 
<b>int</b> *dsts=(<b>int</b>*)malloc(outdegree*<b>sizeof</b>(<b>int</b>)); 
<b>MPI_Dist_graph_neighbors</b>(comm, indegree, srcs, <b>MPI_UNWEIGHTED</b>, 
                         outdegree, dsts, <b>MPI_UNWEIGHTED</b>); 
<b>int</b> k; 
 
/* assume sendbuf and recvbuf are of type (<b>char</b>*) */ 
<b>for</b>(k=0; k&lt;outdegree; ++k) 
  <b>MPI_Isend</b>(sendbuf+sdispls[k], sendcounts[k], sendtypes[k], 
            dsts[k],...); 
 
<b>for</b>(k=0; k&lt;indegree; ++k) 
  <b>MPI_Irecv</b>(recvbuf+rdispls[k], recvcounts[k], recvtypes[k], 
            srcs[k],...); 
 
<b>MPI_Waitall</b>(...); 
</tt></pre> 
  
<P> 
The type signature associated with  
<font face="sans-serif"> sendcounts</font><font face="sans-serif"> [k]</font>, <font face="sans-serif"> sendtypes</font><font face="sans-serif"> [k]</font>  
with <font face="sans-serif"> dsts[k]=<i>j</i></font> at <font face="sans-serif"> MPI</font> process <i>i</i>  
must be equal to the type signature associated with  
<font face="sans-serif"> recvcounts</font><font face="sans-serif"> [l]</font>, <font face="sans-serif"> recvtypes</font><font face="sans-serif"> [l]</font>  
with <font face="sans-serif"> srcs[l]=<i>i</i></font> at <font face="sans-serif"> MPI</font> process <i>j</i>.  
This implies that the amount of data sent must be equal to the  
amount of data received, pairwise between every pair of  
communicating <font face="sans-serif"> MPI</font> processes.  
Distinct type maps between sender and receiver are still allowed.  
 <P> 
The ``in place'' option is not meaningful for this operation.  
<P> 
All arguments are significant on all <font face="sans-serif"> MPI</font> processes and the argument  
<font face="sans-serif"> comm</font> must have identical values on all <font face="sans-serif"> MPI</font> processes.  
<P> 

<P>
<hr>
<a href="node235.htm#Node235"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node234.htm#Node234"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node237.htm#Node237"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node234.htm#Node234"> Neighborhood Collective Communication on Virtual Topologies</a>
<b>Next: </b><a href="node237.htm#Node237"> Nonblocking Neighborhood Communication on Process Topologies</a>
<b>Previous: </b><a href="node235.htm#Node235"> Neighborhood Gather</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
