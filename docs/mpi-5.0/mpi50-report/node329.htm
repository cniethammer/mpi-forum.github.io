<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>Synchronization Calls</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node329">13.5. Synchronization Calls</span></h1>
<a href="node328.htm#Node328"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node308.htm#Node308"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node330.htm#Node330"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node308.htm#Node308"> One-Sided Communications</a>
<b>Next: </b><a href="node330.htm#Node330"> Fence</a>
<b>Previous: </b><a href="node328.htm#Node328"> Memory Model</a>
<p>
  
  
  
<P> 
<font face="sans-serif"> RMA</font> communications fall in two categories:  
<dl> 
 
<dt> 
<b> active target communication,</b><dd> 
 where data is moved from the memory of one  
<font face="sans-serif"> MPI</font> process to the memory of another, and both are explicitly involved in the  
communication.  This communication pattern is similar to message  
passing, except that all the data transfer arguments are provided by  
the origin process, and the target process only participates in the synchronization.  
 
<dt> 
<b> passive target communication,</b><dd> 
 where data is moved from the memory of one  
<font face="sans-serif"> MPI</font> process to the memory of another, and only the origin process is  
explicitly involved  
in  
the transfer.  Thus, two origin processes may communicate by accessing  
the same location in a target window.  The <font face="sans-serif"> MPI</font> process that owns the  
target window may be distinct from the two communicating <font face="sans-serif"> MPI</font> processes,   
in which case it does not participate explicitly in the communication.  
This communication  
paradigm is closest to a shared memory model, where shared data can be  
accessed by all <font face="sans-serif"> MPI</font> processes, irrespective   
of location.  
</dl> 
<br> 
<font face="sans-serif"> RMA</font> communication calls with argument <font face="sans-serif"> win</font> must occur at an origin process  
only within an <b> access epoch</b> for <font face="sans-serif"> win</font>.  Such an epoch  
is opened with an <font face="sans-serif"> RMA</font> synchronization  
call on <font face="sans-serif"> win</font>; it proceeds with zero or more <font face="sans-serif"> RMA</font>  
communication calls (e.g., <font face="sans-serif"> MPI_PUT</font>, <font face="sans-serif"> MPI_GET</font> or  
<font face="sans-serif"> MPI_ACCUMULATE</font>) on <font face="sans-serif"> win</font>; it is closed with another  
synchronization call on   
<font face="sans-serif"> win</font>. This allows users to amortize one synchronization with multiple data  
transfers and provide implementors  
more flexibility in the implementation of <font face="sans-serif"> RMA</font> operations.  
<P> 
Distinct access epochs for <font face="sans-serif"> win</font> at the same <font face="sans-serif"> MPI</font> process must be disjoint.  
On the other hand, epochs pertaining to different <font face="sans-serif"> win</font> arguments  
may  
overlap.  Load/store accesses or other <font face="sans-serif"> MPI</font> calls may also occur during  
an epoch.  
<P> 
In active target communication, a target window can be accessed by <font face="sans-serif"> RMA</font>  
operations only within an <b> exposure epoch</b>. Such an epoch is  
opened and closed by <font face="sans-serif"> RMA</font> synchronization calls executed by the  
target process.  Distinct exposure epochs at an <font face="sans-serif"> MPI</font> process  
on the same window must be disjoint, but such an exposure epoch  
may overlap with exposure epochs on other windows or  
with access epochs for the same or other window arguments.  
There is a one-to-one matching between access epochs at origin  
processes and exposure epochs on target processes:  
<font face="sans-serif"> RMA</font> operations issued by an origin process for a target window will  
access that  
target window during the same exposure epoch if and only if they were  
issued during the same access   
epoch.  
<P> 
In passive target communication the target  
process does not execute <font face="sans-serif"> RMA</font> synchronization calls, and there is no  
concept of an exposure   
epoch.   
<P> 
<font face="sans-serif"> MPI</font> provides three synchronization mechanisms:  
<ol> 
 
1. The  
<font face="sans-serif"> MPI_WIN_FENCE</font> collective synchronization call supports a  
simple synchronization pattern that is often used in parallel  
computations: namely a loosely-synchronous model, where global  
computation phases alternate with global communication phases.  
This mechanism is most useful for loosely synchronous algorithms where  
the graph of communicating <font face="sans-serif"> MPI</font> processes changes very frequently, or where  
each <font face="sans-serif"> MPI</font> process communicates with many   
others.  
<P> 
This call is used for active target communication.  An access epoch at an  
origin process or an exposure epoch at a target process is opened  
and closed by calls to <font face="sans-serif"> MPI_WIN_FENCE</font>.  An origin process can  
access windows at all target processes in the group of <font face="sans-serif"> win</font> during  
such an access  
epoch, and the local window can be accessed by all <font face="sans-serif"> MPI</font> processes in the  
group of <font face="sans-serif"> win</font> during such an exposure epoch.  
 
<br> 
2. The four functions <font face="sans-serif"> MPI_WIN_START</font>,   
<font face="sans-serif"> MPI_WIN_COMPLETE</font>,  
<font face="sans-serif"> MPI_WIN_POST</font>, and  
<font face="sans-serif"> MPI_WIN_WAIT</font>   
can be used to restrict synchronization to the minimum: only  
pairs of communicating <font face="sans-serif"> MPI</font> processes synchronize, and they do so only when  
a synchronization is needed to order <font face="sans-serif"> RMA</font> accesses to a  
window correctly with respect to local accesses to that same window.  
This mechanism may be   
more efficient when each <font face="sans-serif"> MPI</font> process communicates with few (logical)  
neighbors, and the communication graph is fixed or changes  
infrequently.  
<P> 
These calls are used for   
active target communication.  An access epoch is opened  
at the origin process  
with a call to <font face="sans-serif"> MPI_WIN_START</font> and is closed by a call to  
<font face="sans-serif"> MPI_WIN_COMPLETE</font>.  The start call has a group argument  
that specifies the group of target processes for that  
epoch. An exposure epoch is opened at the  
target process by a call  
to <font face="sans-serif"> MPI_WIN_POST</font> and is closed by a call to  
<font face="sans-serif"> MPI_WIN_WAIT</font>.  The post call has a group argument that  
specifies the set of origin processes for that   
epoch.  
 
<br> 
3. Finally, <em> shared lock</em>  
access is provided by the functions <font face="sans-serif"> MPI_WIN_LOCK</font>,  
<font face="sans-serif"> MPI_WIN_LOCK_ALL</font>, <font face="sans-serif"> MPI_WIN_UNLOCK</font>, and  
<font face="sans-serif"> MPI_WIN_UNLOCK_ALL</font>.  <font face="sans-serif"> MPI_WIN_LOCK</font> and  
<font face="sans-serif"> MPI_WIN_UNLOCK</font> also provide <em> exclusive lock</em> capability.  
Lock synchronization  
is useful for <font face="sans-serif"> MPI</font> applications that  
emulate a shared memory model via <font face="sans-serif"> MPI</font> calls; e.g., in a ``bulletin board''  
model, where <font face="sans-serif"> MPI</font> processes can, at random times, access or update  
different parts of the bulletin board.  
<P> 
These four calls provide passive target communication.  An access epoch is  
opened by a call to <font face="sans-serif"> MPI_WIN_LOCK</font> or  
<font face="sans-serif"> MPI_WIN_LOCK_ALL</font> and closed by a call to  
<font face="sans-serif"> MPI_WIN_UNLOCK</font> or <font face="sans-serif"> MPI_WIN_UNLOCK_ALL</font>, respectively.    
</ol> 
<div style="text-align:center"><P><img width=809 height=1370 src="sync15.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 28: </b><span id="Figure28">Active target communication.  Dashed arrows represent 
synchronizations (ordering of events).</span><P> 
  
  
Figure <a href="node329.htm#Figure28">28</a> illustrates the general synchronization  
pattern for active target   
communication.  
The synchronization between  <tt>post</tt> and  
<tt>start</tt> ensures that the put operation of the origin process does  
not start  
until the target process exposes the window (with the <tt>post</tt> call);  
the target process will  
expose the window only after preceding local accesses to the window  
have completed.  
The synchronization between <tt>complete</tt> and <tt>wait</tt>  
ensures that the put operation of the origin process completes at the origin and the target  
before the window is unexposed (with the <tt>wait</tt> call).  
The target process will execute  
subsequent local accesses to the target window only after the <tt>wait</tt>  
returned.  
<P> 
<div style="text-align:center"><P><img width=763 height=1126 src="sync14.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 29: </b><span id="Figure29">Active target communication, with weak synchronization.  Dashed 
arrows represent synchronizations (ordering of events).</span><P> 
  
  
Figure <a href="node329.htm#Figure28">28</a> shows operations occurring in the natural  
temporal order implied by the synchronizations: the <tt>post</tt>  
occurs before the matching <tt>start</tt>, and <tt>complete</tt> occurs before  
the  
matching <tt>wait</tt>.  However, such <b> strong synchronization</b> is more  
than  
needed for correct ordering of window accesses.  The semantics of  
<font face="sans-serif"> MPI</font> calls allow <b> weak synchronization</b>,   
as illustrated in Figure <a href="node329.htm#Figure29">29</a>.  
The access to the target window  is delayed until the window is  
exposed, after the <tt>post</tt>. However the <tt>start</tt>  
may return before the exposure epoch opens at the target. Similarly, the <tt>put</tt> and   
<tt>complete</tt> calls may also return before the exposure epoch opens at the target, if put data is  
buffered by the implementation.  
The synchronization calls correctly order window accesses, but do not  
necessarily synchronize other operations.  This weaker synchronization  
semantic allows for more efficient   
implementations.  
<P> 
<div style="text-align:center"><P><img width=1170 height=1478 src="sync23.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 30: </b><span id="Figure30">Passive target communication.  Dashed arrows represent 
synchronizations (ordering of events).</span><P> 
  
  
Figure <a href="node329.htm#Figure30">30</a> illustrates the general synchronization  
pattern for passive target   
communication.  
The first origin process communicates data to the second  
origin process, through the memory of the target process; the target  
process is not explicitly involved in the   
communication.  
The  
<tt>lock</tt> and <tt>unlock</tt> calls ensure that the two <font face="sans-serif"> RMA</font>  
accesses do not occur concurrently. However, they do <em> not</em> ensure  
that the <tt>put</tt> by origin 1 will precede the <tt>get</tt> by   
origin 2.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
<font face="sans-serif"> RMA</font> does not define fine-grained mutexes in memory (only logical  
coarse-grained window locks). <font face="sans-serif"> MPI</font> provides the primitives (compare  
and swap, accumulate, send/receive, etc.) needed to implement high-level  
synchronization operations.  
 (<em> End of rationale.</em>) <br> 
<ul> 
</ul> 

<P>
<hr>
<a href="node328.htm#Node328"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node308.htm#Node308"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node330.htm#Node330"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node308.htm#Node308"> One-Sided Communications</a>
<b>Next: </b><a href="node330.htm#Node330"> Fence</a>
<b>Previous: </b><a href="node328.htm#Node328"> Memory Model</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
