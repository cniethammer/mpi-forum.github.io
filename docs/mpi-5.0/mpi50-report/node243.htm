<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-topol/topol-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>An Application Example</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node243">9.9. An Application Example</span></h1>
<a href="node242.htm#Node242"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node220.htm#Node220"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node244.htm#Node244"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node220.htm#Node220"> Virtual Topologies for <font face="sans-serif"> MPI</font> Processes</a>
<b>Next: </b><a href="node244.htm#Node244"> <font face="sans-serif"> MPI</font> Environmental Management</a>
<b>Previous: </b><a href="node242.htm#Node242"> Persistent Neighborhood Alltoall</a>
<p>
  
<P> 
<br><b> Example</b>  
  
Neighborhood collective communication in a Cartesian virtual topology.  
<P> 
The example in   
Listings --  
shows how the grid definition and  
inquiry functions can be used in an application program. A partial  
differential equation, for instance the Poisson equation, is to be  
solved on a rectangular domain.  
First, the <font face="sans-serif"> MPI</font> processes organize themselves in a two-dimensional  
structure. Each <font face="sans-serif"> MPI</font> process then inquires about the ranks of its  
neighbors in the four directions (up, down, right, left).  
The numerical problem is solved by an iterative method, the details  
of which are hidden in the subroutine <tt>relax</tt>.  
<P> 
In each relaxation step each <font face="sans-serif"> MPI</font> process computes new values for the solution grid  
function at the points <tt>u(1:100,1:100)</tt>  
owned by the <font face="sans-serif"> MPI</font> process. Then the values at inter-process  
boundaries have to be exchanged with neighboring <font face="sans-serif"> MPI</font> processes.  
For example, the  
newly calculated values in <tt>u(1,1:100)</tt>  
must be sent into the halo cells <tt>u(101,1:100)</tt>  
of the left-hand neighbor with coordinates <tt>(own_coord(1)-1,own_coord(2))</tt>.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>INTEGER</b> ndims, num_neigh 
LOGICAL reorder 
PARAMETER (ndims=2, num_neigh=4, reorder=.true.) 
<b>INTEGER</b> comm, comm_size, comm_cart, dims(ndims), ierr 
<b>INTEGER</b> neigh_rank(num_neigh), own_coords(ndims), i, j, it 
LOGICAL periods(ndims) 
<b>REAL</b> u(0:101,0:101), f(0:101,0:101) 
<b>DATA</b> dims / ndims * 0 / 
comm = <b>MPI_COMM_WORLD</b> 
<b>CALL</b> <b>MPI_COMM_SIZE</b>(comm, comm_size, ierr) 
!   Set MPI process grid size and periodicity 
<b>CALL</b> <b>MPI_DIMS_CREATE</b>(comm_size, ndims, dims, ierr) 
periods(1) = .TRUE. 
periods(2) = .TRUE. 
!   Create a grid structure <b>in</b> WORLD group and inquire about own position 
<b>CALL</b> <b>MPI_CART_CREATE</b>(comm, ndims, dims, periods, reorder, &amp; 
                     comm_cart, ierr) 
<b>CALL</b> <b>MPI_CART_GET</b>(comm_cart, ndims, dims, periods, own_coords, ierr) 
i = own_coords(1) 
j = own_coords(2) 
! Look up the ranks for the neighbors.  Own MPI process coordinates are (i,j). 
! Neighbors are (i-1,j), (i+1,j), (i,j-1), (i,j+1) modulo (dims(1),dims(2)) 
<b>CALL</b> <b>MPI_CART_SHIFT</b>(comm_cart, 0,1, neigh_rank(1), neigh_rank(2), ierr) 
<b>CALL</b> <b>MPI_CART_SHIFT</b>(comm_cart, 1,1, neigh_rank(3), neigh_rank(4), ierr) 
! Initialize the grid functions and start the iteration 
<b>CALL</b> init(u, f) 
<b>DO</b> it=1,100 
   <b>CALL</b> relax(u, f) 
!      Exchange <b>data</b> with neighbor processes 
   <b>CALL</b> exchange(u, comm_cart, neigh_rank, num_neigh) 
<b>END</b> <b>DO</b> 
<b>CALL</b> output(u) 
</tt></pre> 
  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>SUBROUTINE</b> exchange(u, comm_cart, neigh_rank, num_neigh) 
<b>USE</b> MPI 
<b>REAL</b> u(0:101,0:101) 
<b>INTEGER</b> comm_cart, num_neigh, neigh_rank(num_neigh) 
<b>REAL</b> sndbuf(100,num_neigh), rcvbuf(100,num_neigh) 
<b>INTEGER</b> ierr 
sndbuf(1:100,1) = u(  1,1:100) 
sndbuf(1:100,2) = u(100,1:100) 
sndbuf(1:100,3) = u(1:100,  1) 
sndbuf(1:100,4) = u(1:100,100) 
<b>CALL</b> <b>MPI_NEIGHBOR_ALLTOALL</b>(sndbuf, 100, <b>MPI_REAL</b>, rcvbuf, 100, <b>MPI_REAL</b>, &amp; 
                           comm_cart, ierr) 
! instead of 
! <b>CALL</b> <b>MPI_IRECV</b>(rcvbuf(1,1),100,<b>MPI_REAL</b>, neigh_rank(1),..., rq(1), ierr) 
! <b>CALL</b> <b>MPI_ISEND</b>(sndbuf(1,2),100,<b>MPI_REAL</b>, neigh_rank(2),..., rq(2), ierr) 
!   Always pairing a receive from rank_source with a send to rank_dest 
!   of the same direction <b>in</b> <b>MPI_CART_SHIFT</b>! 
! <b>CALL</b> <b>MPI_IRECV</b>(rcvbuf(1,2),100,<b>MPI_REAL</b>, neigh_rank(2),..., rq(3), ierr) 
! <b>CALL</b> <b>MPI_ISEND</b>(sndbuf(1,1),100,<b>MPI_REAL</b>, neigh_rank(1),..., rq(4), ierr) 
! <b>CALL</b> <b>MPI_IRECV</b>(rcvbuf(1,3),100,<b>MPI_REAL</b>, neigh_rank(3),..., rq(5), ierr) 
! <b>CALL</b> <b>MPI_ISEND</b>(sndbuf(1,4),100,<b>MPI_REAL</b>, neigh_rank(4),..., rq(6), ierr) 
! <b>CALL</b> <b>MPI_IRECV</b>(rcvbuf(1,4),100,<b>MPI_REAL</b>, neigh_rank(4),..., rq(7), ierr) 
! <b>CALL</b> <b>MPI_ISEND</b>(sndbuf(1,3),100,<b>MPI_REAL</b>, neigh_rank(3),..., rq(8), ierr) 
!   Of course, one can first start all four IRECV and <b>then</b> all four ISEND, 
!   Or vice versa, but both <b>in</b> the sequence shown above. Otherwise, the 
!   matching would be wrong for 2 or <b>only</b> 1 MPI processes <b>in</b> a direction. 
! <b>CALL</b> <b>MPI_WAITALL</b>(2*num_neigh, rq, statuses, ierr) 
u(  0,1:100) = rcvbuf(1:100,1) 
u(101,1:100) = rcvbuf(1:100,2) 
u(1:100,  0) = rcvbuf(1:100,3) 
u(1:100,101) = rcvbuf(1:100,4) 
<b>END</b> 
</tt></pre> 
  
<P> 
<span style="font-size:0.900em;">  
<br> 
<pre style="background-color:#EFEFEF"><tt><b>SUBROUTINE</b> exchange(u, comm_cart, neigh_rank, num_neigh) 
<b>USE</b> MPI 
<b>IMPLICIT</b> <b>NONE</b> 
<b>REAL</b> u(0:101,0:101) 
<b>INTEGER</b> comm_cart, num_neigh, neigh_rank(num_neigh) 
<b>INTEGER</b> sndcounts(num_neigh), sndtypes(num_neigh) 
<b>INTEGER</b> rcvcounts(num_neigh), rcvtypes(num_neigh) 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lb, sizeofreal 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) sdispls(num_neigh), rdispls(num_neigh) 
<b>INTEGER</b> type_vec, ierr 
! The following initialization need to be done <b>only</b> once 
! before the first <b>call</b> of exchange. 
<b>CALL</b> <b>MPI_TYPE_GET_EXTENT</b>(<b>MPI_REAL</b>, lb, sizeofreal, ierr) 
<b>CALL</b> <b>MPI_TYPE_VECTOR</b>(100, 1, 102, <b>MPI_REAL</b>, type_vec, ierr) 
<b>CALL</b> <b>MPI_TYPE_COMMIT</b>(type_vec, ierr) 
sndtypes(1:2) = type_vec 
sndcounts(1:2) = 1 
sndtypes(3:4) = <b>MPI_REAL</b> 
sndcounts(3:4) = 100 
rcvtypes = sndtypes 
rcvcounts = sndcounts 
sdispls(1) = ( 1  +   1*102) * sizeofreal ! first element of u(  1    ,  1:100) 
sdispls(2) = (100 +   1*102) * sizeofreal ! first element of u(100    ,  1:100) 
sdispls(3) = ( 1  +   1*102) * sizeofreal ! first element of u(  1:100,  1    ) 
sdispls(4) = ( 1  + 100*102) * sizeofreal ! first element of u(  1:100,100    ) 
rdispls(1) = ( 0  +   1*102) * sizeofreal ! first element of u(  0    ,  1:100) 
rdispls(2) = (101 +   1*102) * sizeofreal ! first element of u(101    ,  1:100) 
rdispls(3) = ( 1  +   0*102) * sizeofreal ! first element of u(  1:100,  0    ) 
rdispls(4) = ( 1  + 101*102) * sizeofreal ! first element of u(  1:100,101    ) 
! the following communication has to be done <b>in</b> each <b>call</b> of exchange 
<b>CALL</b> <b>MPI_NEIGHBOR_ALLTOALLW</b>(u, sndcounts, sdispls, sndtypes, &amp; 
                            u, rcvcounts, rdispls, rcvtypes, &amp; 
                            comm_cart, ierr) 
! The following finalizing need to be done <b>only</b> once 
! after the last <b>call</b> of exchange. 
<b>CALL</b> <b>MPI_TYPE_FREE</b>(type_vec, ierr) 
<b>END</b> 
</tt></pre> 
  
</span>  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>INTEGER</b> ndims, num_neigh 
LOGICAL reorder 
PARAMETER (ndims=2, num_neigh=4, reorder=.true.) 
<b>INTEGER</b> comm, comm_size, comm_cart, dims(ndims), it, ierr 
LOGICAL periods(ndims) 
<b>REAL</b> u(0:101,0:101), f(0:101,0:101) 
<b>DATA</b> dims / ndims * 0 / 
<b>INTEGER</b> sndcounts(num_neigh), sndtypes(num_neigh) 
<b>INTEGER</b> rcvcounts(num_neigh), rcvtypes(num_neigh) 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lb, sizeofreal 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) sdispls(num_neigh), rdispls(num_neigh) 
<b>INTEGER</b> type_vec, request, info, status(<b>MPI_STATUS_SIZE</b>) 
comm = <b>MPI_COMM_WORLD</b> 
<b>CALL</b> <b>MPI_COMM_SIZE</b>(comm, comm_size, ierr) 
!   Set MPI process grid size and periodicity 
<b>CALL</b> <b>MPI_DIMS_CREATE</b>(comm_size, ndims, dims, ierr) 
periods(1) = .TRUE. 
periods(2) = .TRUE. 
!   Create a grid structure <b>in</b> WORLD group 
<b>CALL</b> <b>MPI_CART_CREATE</b>(comm, ndims, dims, periods, reorder, &amp; 
                     comm_cart, ierr) 
! Create datatypes for the neighborhood communication 
! 
! Insert code from example <b>in</b> Listing (*@\ref{poisson-<b>end</b>}@*) to create and initialize 
! sndcounts, sdispls, sndtypes, rcvcounts, rdispls, and rcvtypes 
! 
! Initialize the neighborhood alltoallw operation 
info = <b>MPI_INFO_NULL</b> 
<b>CALL</b> <b>MPI_NEIGHBOR_ALLTOALLW_INIT</b>(u, sndcounts, sdispls, sndtypes, &amp; 
                                 u, rcvcounts, rdispls, rcvtypes, &amp; 
                                 comm_cart, info, request, ierr) 
! Initialize the grid functions and start the iteration 
<b>CALL</b> init(u, f) 
<b>DO</b> it=1,100 
!      Start <b>data</b> exchange with neighbor processes 
   <b>CALL</b> <b>MPI_START</b>(request, ierr) 
!      Compute inner cells 
   <b>CALL</b> relax_inner (u, f) 
!      Check on completion of neighbor exchange 
   <b>CALL</b> <b>MPI_WAIT</b>(request, status, ierr) 
!      Compute edge cells 
   <b>CALL</b> relax_edges(u, f) 
<b>END</b> <b>DO</b> 
<b>CALL</b> output(u) 
<b>CALL</b> <b>MPI_REQUEST_FREE</b>(request, ierr) 
<b>CALL</b> <b>MPI_TYPE_FREE</b>(type_vec, ierr) 
</tt></pre> 
  
  
<P> 
<P> 
<P> 
  

<P>
<hr>
<a href="node242.htm#Node242"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node220.htm#Node220"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node244.htm#Node244"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node220.htm#Node220"> Virtual Topologies for <font face="sans-serif"> MPI</font> Processes</a>
<b>Next: </b><a href="node244.htm#Node244"> <font face="sans-serif"> MPI</font> Environmental Management</a>
<b>Previous: </b><a href="node242.htm#Node242"> Persistent Neighborhood Alltoall</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
