<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>Progress</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node342">13.7.3. Progress</span></h2>
<a href="node341.htm#Node341"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node339.htm#Node339"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node343.htm#Node343"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node339.htm#Node339"> Semantics and Correctness</a>
<b>Next: </b><a href="node343.htm#Node343"> Registers and Compiler Optimizations</a>
<b>Previous: </b><a href="node341.htm#Node341"> Ordering</a>
<p>
  
  
  
  
<P> 
One-sided communication has the same progress requirements as  
point-to-point communication: once a communication is enabled it  
is guaranteed to complete.  <font face="sans-serif"> RMA</font> calls must have local semantics,  
except when required for synchronization with other <font face="sans-serif"> RMA</font> calls.  
<P> 
There is some fuzziness in the definition of the time when an <font face="sans-serif"> RMA</font>  
communication  
becomes enabled.  This fuzziness provides to the implementor more  
flexibility  
than with point-to-point communication.  
Access to a target window becomes enabled once the corresponding synchronization (such as <font face="sans-serif"> MPI_WIN_FENCE</font> or <font face="sans-serif"> MPI_WIN_POST</font>) has executed.  On the origin process, an <font face="sans-serif"> RMA</font>  
communication operation may become enabled as soon as the corresponding put, get  
or accumulate call has occurred, or as late as when  
the ensuing synchronization call is issued.  Once the  
operation is enabled both at the origin and at the target, the operation must complete.  
<P> 
Consider the code fragment in Example <a href="node331.htm#Node331">General Active Target Synchronization</a>.  
Some of  
the calls may have to delay their return until the target window has been posted.  However, if  
the target window is posted, then the code fragment must complete.  
The data transfer may start as soon as the put call occurs, but may be delayed until the ensuing complete call occurs.  
<P> 
Consider the code fragment in Example <a href="node332.htm#Node332">Lock</a>.  
Some of the calls may delay their return until the lock is acquired if another <font face="sans-serif"> MPI</font> process holds a conflicting  
lock.  However, if no conflicting lock is held, then the code fragment  
must complete.  
<P> 
Consider the code illustrated  in  
Figure <a href="node342.htm#Figure32">32</a>.  
<div style="text-align:center"><P><img width=578 height=465 src="symmetric.gif" alt="Image file"><P>
</div>  
<br> 
<b>Figure 32: </b><span id="Figure32">Symmetric communication</span><P> 
  
  
Each <font face="sans-serif"> MPI</font> process updates the window of the other <font face="sans-serif"> MPI</font> process using a put  
operation, then accesses its own window.  The post calls are  
local.  Once the post calls occur, <font face="sans-serif"> RMA</font>  
access to the windows is enabled, so that each <font face="sans-serif"> MPI</font> process should complete  
the sequence of start-put-complete.  Once these are done,  
the wait calls should complete at both <font face="sans-serif"> MPI</font> processes.  Thus, this  
communication should not deadlock, irrespective of the amount of data   
transferred.  
<P> 
Assume, in the last example, that the order of the post and start  
calls is reversed at each <font face="sans-serif"> MPI</font> process.  
Then, the code may deadlock, as  
each <font face="sans-serif"> MPI</font> process may not return from the start call, waiting for the matching post  
to occur.  
Similarly, the program will deadlock if the  
order of the complete and   
wait calls is reversed at each <font face="sans-serif"> MPI</font> process.  
<P> 
The following two examples illustrate the fact that the  
synchronization between complete and wait is not symmetric: the wait  
call returns only once the complete occurs, but not vice versa.  
Consider the code illustrated in Figure <a href="node342.htm#Figure33">33</a>.  
<div style="text-align:center"><P><img width=537 height=317 src="deadlck1.gif" alt="Image file"><P>
</div>  
<P> 
<br> 
<b>Figure 33: </b><span id="Figure33">Deadlock situation</span><P> 
  
  
This code will deadlock: the wait of process 1 completes only once process 0  
calls complete, and the receive of process 0 completes once process 1  
calls send.  Consider, on the other hand, the code  
illustrated in Figure <a href="node342.htm#Figure34">34</a>.  
<div style="text-align:center"><P><img width=494 height=315 src="deadlck2.gif" alt="Image file"><P>
</div>  
<P> 
<br> 
<b>Figure 34: </b><span id="Figure34">No deadlock</span><P> 
  
  
This code will not deadlock.  Once process 1 calls post, then the  
sequence start-put-complete on process 0 can proceed.  
Process 0 will reach the send call, allowing the receive call of  
process 1 to return.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
<font face="sans-serif"> MPI</font> implementations must guarantee that an <font face="sans-serif"> MPI</font> process makes   
<em> progress</em>  
on all enabled communications it participates in,  
while blocked on an <font face="sans-serif"> MPI</font> call.  This is  
true for send-receive communication and applies to <font face="sans-serif"> RMA</font> communication  
as well.  Thus, in the example in Figure <a href="node342.htm#Figure34">34</a>,  
the put and complete calls of process 0 should complete  
while process 1 is waiting for the receive operation to complete.  This may require the  
involvement of process 1, e.g., to transfer the data.  
<P> 
A similar issue is whether such progress must occur  
while an <font face="sans-serif"> MPI</font> process is busy computing, or blocked in a  
non-<font face="sans-serif"> MPI</font> call.  Suppose that in the last example the send-receive  
pair is replaced by a write-to-socket/read-from-socket pair.  Then  
<font face="sans-serif"> MPI</font> does not specify whether deadlock is avoided.  
Suppose that the blocking  
receive of process 1 is replaced by a very long compute loop.  Then,  
according to one interpretation of  
the <font face="sans-serif"> MPI</font> standard, process 0 must return from the complete call after  
a bounded delay, even if process 1 does not reach any <font face="sans-serif"> MPI</font> call in  
this period of time.  According to another interpretation, the  
complete call may block until process 1 reaches the wait call, or  
reaches another <font face="sans-serif"> MPI</font> call.  The qualitative behavior is the same,  
under both interpretations, unless an <font face="sans-serif"> MPI</font> process is caught in an infinite compute loop, in which case the difference may not matter.  
However, the quantitative expectations are different.  
Different <font face="sans-serif"> MPI</font> implementations reflect these different  
interpretations.  
While this ambiguity is unfortunate, the <font face="sans-serif"> MPI</font> Forum decided not to define  
which interpretation of the standard is the correct one, since the issue is  
contentious.  
See also Section <a href="node50.htm#Node50">Progress</a> on  
<em> progress</em>.  
 (<em> End of rationale.</em>) <br> 
The use of shared memory loads  
and/or stores for synchronizing  
purposes between <font face="sans-serif"> MPI</font> processes does not guarantee progress, and therefore  
a <em> deadlock</em> may occur if an <font face="sans-serif"> MPI</font> implementation  
does not provide <em> strong progress</em>, as shown in Example <a href="node342.htm#Node342">Progress</a>.  
<P> 
<br><b> Example</b>  
  
Possible <em> deadlock</em> due to the use of a shared memory variable for synchronization.  
<P> 
<tt>comm_sm</tt> shall be a shared memory communicator (e.g., returned from a call to  
<font face="sans-serif"> MPI_COMM_SPLIT_TYPE</font> with <font face="sans-serif"> split_type</font><font face="sans-serif"> =</font><font face="sans-serif"> MPI_COMM_TYPE_SHARED</font>)    
with at least two <font face="sans-serif"> MPI</font> processes.  
<tt>win_sm</tt> is a shared memory window with the <tt>AckInRank0</tt> as  
window portion in <font face="sans-serif"> MPI</font> process with rank <font face="sans-serif"> 0</font>.  
The ranks in <tt>comm_sm</tt> and <tt>win_sm</tt> should be the same.  
According to Section <a href="node339.htm#Node339">Semantics and Correctness</a> rules U<a href="node339.htm#Node339">Semantics and Correctness</a> and U<a href="node339.htm#Node339">Semantics and Correctness</a>,  
a volatile store to <tt>AckInRank0</tt> will be visible in the  
other <font face="sans-serif"> MPI</font> process without further <font face="sans-serif"> RMA</font> calls.  
<P> 
  
<P><img width=903 height=541 src="img52.gif" alt="Image file"><P>
  
<P> 
While the call to <font face="sans-serif"> MPI_Recv</font> in the <font face="sans-serif"> MPI</font> process with rank <font face="sans-serif"> 1</font> delays its return  
(until an unspecific <font face="sans-serif"> MPI</font> procedure call in the <font face="sans-serif"> MPI</font> process with rank <font face="sans-serif"> 0</font> happens to send  
the buffered data), the subsequent statement cannot change the value of the  
shared window buffer <tt>AckInRank0</tt>.  
As long as this value is not changed, the while loop in the <font face="sans-serif"> MPI</font> process with rank <font face="sans-serif"> 0</font>  
will continue and therefore the next <font face="sans-serif"> MPI</font> procedure call  
(<font face="sans-serif"> MPI_Buffer_detach</font>) cannot happen, which is then a <em> deadlock</em>.  
  
<P> 
Note that both communication patterns  
(A) <font face="sans-serif"> BSEND-RECV-DETACH</font>  
and  
(B) the shared memory store/load for synchronization purpose,  
can be in different software layers and each layer would work properly,  
but the combination of (A) and (B) can cause the <em> deadlock</em>.   
<P> 

<P>
<hr>
<a href="node341.htm#Node341"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node339.htm#Node339"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node343.htm#Node343"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node339.htm#Node339"> Semantics and Correctness</a>
<b>Next: </b><a href="node343.htm#Node343"> Registers and Compiler Optimizations</a>
<b>Previous: </b><a href="node341.htm#Node341"> Ordering</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
