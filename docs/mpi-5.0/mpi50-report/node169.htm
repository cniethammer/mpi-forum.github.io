<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>Persistent All-Reduce</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node169">7.13.8. Persistent All-Reduce</span></h2>
<a href="node168.htm#Node168"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node161.htm#Node161"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node170.htm#Node170"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node161.htm#Node161"> Persistent Collective Operations</a>
<b>Next: </b><a href="node170.htm#Node170"> Persistent Reduce-Scatter with Equal Blocks</a>
<b>Previous: </b><a href="node168.htm#Node168"> Persistent Reduce</a>
<p>
  
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_ALLREDUCE_INIT(<span style="white-space:nowrap">sendbuf</span>, <span style="white-space:nowrap">recvbuf</span>, <span style="white-space:nowrap">count</span>, <span style="white-space:nowrap">datatype</span>, <span style="white-space:nowrap">op</span>, <span style="white-space:nowrap">comm</span>, <span style="white-space:nowrap">info</span>, <span style="white-space:nowrap">request</span>)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> sendbuf</TD><TD>starting address of send buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> OUT</span> recvbuf</TD><TD>starting address of receive buffer (choice)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> count</TD><TD>number of elements in send buffer (nonnegative integer)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> datatype</TD><TD>datatype of elements of send buffer (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> op</TD><TD>operation (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> comm</TD><TD>communicator (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> IN</span> info</TD><TD>info argument (handle)</TD></TR>  
<TR><TD><span style="font-size:0.900em;"> OUT</span> request</TD><TD>communication request (handle)</TD></TR>  
</TABLE>  
  <b> C binding</b><br>  <tt> int MPI_Allreduce_init(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm, MPI_Info info, MPI_Request *request) <br></tt>  
  
  <tt> int MPI_Allreduce_init_c(const void *sendbuf, void *recvbuf, MPI_Count count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm, MPI_Info info, MPI_Request *request) <br></tt>  
  <b> Fortran 2008 binding</b><br>  <tt> MPI_Allreduce_init(sendbuf, recvbuf, count, datatype, op, comm, info, request, ierror) <br> TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: <span style="white-space:nowrap">sendbuf</span><br>TYPE(*), DIMENSION(..), ASYNCHRONOUS :: <span style="white-space:nowrap">recvbuf</span><br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">count</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">datatype</span><br>TYPE(MPI_Op), INTENT(IN) :: <span style="white-space:nowrap">op</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>TYPE(MPI_Info), INTENT(IN) :: <span style="white-space:nowrap">info</span><br>TYPE(MPI_Request), INTENT(OUT) :: <span style="white-space:nowrap">request</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <tt> MPI_Allreduce_init(sendbuf, recvbuf, count, datatype, op, comm, info, request, ierror) !(_c) <br> TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: <span style="white-space:nowrap">sendbuf</span><br>TYPE(*), DIMENSION(..), ASYNCHRONOUS :: <span style="white-space:nowrap">recvbuf</span><br>INTEGER(KIND=MPI_COUNT_KIND), INTENT(IN) :: <span style="white-space:nowrap">count</span><br>TYPE(MPI_Datatype), INTENT(IN) :: <span style="white-space:nowrap">datatype</span><br>TYPE(MPI_Op), INTENT(IN) :: <span style="white-space:nowrap">op</span><br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span><br>TYPE(MPI_Info), INTENT(IN) :: <span style="white-space:nowrap">info</span><br>TYPE(MPI_Request), INTENT(OUT) :: <span style="white-space:nowrap">request</span><br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <b> Fortran binding</b><br>  <tt> MPI_ALLREDUCE_INIT(SENDBUF, RECVBUF, COUNT, DATATYPE, OP, COMM, INFO, REQUEST, IERROR) <br> &lt;type&gt; <span style="white-space:nowrap">SENDBUF(*)</span>, <span style="white-space:nowrap">RECVBUF(*)</span><br>INTEGER <span style="white-space:nowrap">COUNT</span>, <span style="white-space:nowrap">DATATYPE</span>, <span style="white-space:nowrap">OP</span>, <span style="white-space:nowrap">COMM</span>, <span style="white-space:nowrap">INFO</span>, <span style="white-space:nowrap">REQUEST</span>, <span style="white-space:nowrap">IERROR</span> <br></tt>  
<P> 
Creates a persistent collective communication request for the allreduce operation  
(see Section <a href="node138.htm#Node138">All-Reduce</a>).  
<P> 

<P>
<hr>
<a href="node168.htm#Node168"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node161.htm#Node161"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node170.htm#Node170"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node161.htm#Node161"> Persistent Collective Operations</a>
<b>Next: </b><a href="node170.htm#Node170"> Persistent Reduce-Scatter with Equal Blocks</a>
<b>Previous: </b><a href="node168.htm#Node168"> Persistent Reduce</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
