<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi5-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi50-report-html.idx --lstlisting -basedef mpi5defs.txt -o mpi50-report.tex mpi-reporthtml.tex 
-->
<title>Examples for Communication Calls</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node321">13.3.3. Examples for Communication Calls</span></h2>
<a href="node320.htm#Node320"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node318.htm#Node318"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node322.htm#Node322"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node318.htm#Node318"> Communication Calls</a>
<b>Next: </b><a href="node322.htm#Node322"> Accumulate Functions</a>
<b>Previous: </b><a href="node320.htm#Node320"> Get</a>
<p>
  
<P> 
These examples show the use of the <font face="sans-serif"> MPI_GET</font> procedure.  
  As all <font face="sans-serif"> MPI</font> <font face="sans-serif"> RMA</font> communication procedures are nonblocking, the associated operations  
  must be completed by subsequent calls to synchronization procedures.  
  In the following example, completion is accomplished with the  
  routine <font face="sans-serif"> MPI_WIN_FENCE</font>, introduced in  
  Section <a href="node329.htm#Node329">Synchronization Calls</a>.  
<P> 
<br><b> Example</b>  
  
We show how to implement the generic indirect assignment  
<tt>A = B(map)</tt>, where <tt>A</tt>,  
<tt>B</tt>, and   
<tt>map</tt> have the same  
distribution, and <tt>map</tt> is a permutation.  To simplify, we assume  
a block distribution with equal size   
blocks.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>SUBROUTINE</b> MAPVALS(A, B, map, m, comm, p) 
<b>USE</b> MPI 
<b>INTEGER</b> m, map(m), comm, p 
<b>REAL</b> A(m), B(m) 
 
<b>INTEGER</b> otype(p), oindex(m),   &amp; ! used to construct origin datatypes 
     ttype(p), tindex(m),      &amp; ! used to construct target datatypes 
     count(p), total(p),       &amp; 
     disp_int, win, ierr, i, j, k 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lowerbound, size, realextent, disp_aint 
 
! This part does the work that depends on the locations of B. 
! Can be reused <b>while</b> this does not change 
 
<b>CALL</b> <b>MPI_TYPE_GET_EXTENT</b>(<b>MPI_REAL</b>, lowerbound, realextent, ierr) 
disp_int = realextent 
size = m * realextent 
<b>CALL</b> <b>MPI_WIN_CREATE</b>(B, size, disp_int, <b>MPI_INFO_NULL</b>,   &amp; 
                    comm, win, ierr) 
 
! This part does the work that depends on the value of map and 
! the locations of the arrays. 
! Can be reused <b>while</b> these <b>do</b> not change 
 
! Compute number of entries to be received from each process 
 
<b>DO</b> i=1,p 
   count(i) = 0 
<b>END</b> <b>DO</b> 
<b>DO</b> i=1,m 
   j = map(i)/m+1 
   count(j) = count(j)+1 
<b>END</b> <b>DO</b> 
 
total(1) = 0 
<b>DO</b> i=2,p 
   total(i) = total(i-1) + count(i-1) 
<b>END</b> <b>DO</b> 
 
<b>DO</b> i=1,p 
   count(i) = 0 
<b>END</b> <b>DO</b> 
 
! compute origin and target indices of entries. 
! entry i at current process is received from location 
! k at process (j-1), where map(i) = (j-1)*m + (k-1), 
! j = 1..p and k = 1..m 
 
<b>DO</b> i=1,m 
   j = map(i)/m+1 
   k = MOD(map(i),m)+1 
   count(j) = count(j)+1 
   oindex(total(j) + count(j)) = i 
   tindex(total(j) + count(j)) = k 
<b>END</b> <b>DO</b> 
 
! create origin and target datatypes for each get operation 
<b>DO</b> i=1,p 
   <b>CALL</b> <b>MPI_TYPE_CREATE_INDEXED_BLOCK</b>(count(i), 1, &amp; 
                                      oindex(total(i)+1:total(i)+count(i)), &amp; 
                                      <b>MPI_REAL</b>, otype(i), ierr) 
   <b>CALL</b> <b>MPI_TYPE_COMMIT</b>(otype(i), ierr) 
   <b>CALL</b> <b>MPI_TYPE_CREATE_INDEXED_BLOCK</b>(count(i), 1, &amp; 
                                      tindex(total(i)+1:total(i)+count(i)), &amp; 
                                      <b>MPI_REAL</b>, ttype(i), ierr) 
   <b>CALL</b> <b>MPI_TYPE_COMMIT</b>(ttype(i), ierr) 
<b>END</b> <b>DO</b> 
 
! this part does the assignment itself 
<b>CALL</b> <b>MPI_WIN_FENCE</b>(0, win, ierr) 
disp_aint = 0 
<b>DO</b> i=1,p 
   <b>CALL</b> <b>MPI_GET</b>(A, 1, otype(i), i-1, disp_aint, 1, ttype(i), win, ierr) 
<b>END</b> <b>DO</b> 
<b>CALL</b> <b>MPI_WIN_FENCE</b>(0, win, ierr) 
 
<b>CALL</b> <b>MPI_WIN_FREE</b>(win, ierr) 
<b>DO</b> i=1,p 
   <b>CALL</b> <b>MPI_TYPE_FREE</b>(otype(i), ierr) 
   <b>CALL</b> <b>MPI_TYPE_FREE</b>(ttype(i), ierr) 
<b>END</b> <b>DO</b> 
<b>RETURN</b> 
<b>END</b> 
</tt></pre> 
  
  
<P> 
<br><b> Example</b>  
  
A simpler version can be written that does not require that a  
datatype be built for the target buffer.  One then needs a  
separate get operation for each entry,  
as illustrated below.  This code is much simpler, but usually much less  
efficient, for large arrays.  
<P> 
<br> 
<pre style="background-color:#EFEFEF"><tt><b>SUBROUTINE</b> MAPVALS(A, B, map, m, comm, p) 
<b>USE</b> MPI 
<b>INTEGER</b> m, map(m), comm, p 
<b>REAL</b> A(m), B(m) 
<b>INTEGER</b> disp_int, i, j, win, ierr 
<b>INTEGER</b>(<b>KIND</b>=<b>MPI_ADDRESS_KIND</b>) lowerbound, size, realextent, disp_aint 
 
<b>CALL</b> <b>MPI_TYPE_GET_EXTENT</b>(<b>MPI_REAL</b>, lowerbound, realextent, ierr) 
disp_int = realextent 
size = m * realextent 
<b>CALL</b> <b>MPI_WIN_CREATE</b>(B, size, disp_int, <b>MPI_INFO_NULL</b>,  &amp; 
                    comm, win, ierr) 
 
<b>CALL</b> <b>MPI_WIN_FENCE</b>(0, win, ierr) 
<b>DO</b> i=1,m 
   j = map(i)/m 
   disp_aint = MOD(map(i),m) 
   <b>CALL</b> <b>MPI_GET</b>(A(i), 1, <b>MPI_REAL</b>, j, disp_aint, 1, <b>MPI_REAL</b>, win, ierr) 
<b>END</b> <b>DO</b> 
<b>CALL</b> <b>MPI_WIN_FENCE</b>(0, win, ierr) 
<b>CALL</b> <b>MPI_WIN_FREE</b>(win, ierr) 
<b>RETURN</b> 
<b>END</b> 
</tt></pre> 
  
  
<P> 

<P>
<hr>
<a href="node320.htm#Node320"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node318.htm#Node318"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node322.htm#Node322"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node318.htm#Node318"> Communication Calls</a>
<b>Next: </b><a href="node322.htm#Node322"> Accumulate Functions</a>
<b>Previous: </b><a href="node320.htm#Node320"> Get</a>
<p>
<HR>
Return to <A HREF="node627.htm">MPI-5.0 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-5.0 of June 9, 2025<BR>
HTML Generated on March 2, 2025
</FONT>
</body>
</html>
